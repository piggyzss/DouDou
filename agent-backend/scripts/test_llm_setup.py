#!/usr/bin/env python3
"""
æµ‹è¯• LLM è®¾ç½®è„šæœ¬
éªŒè¯ Gemini API é…ç½®æ˜¯å¦æ­£ç¡®
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from loguru import logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def test_environment():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("=" * 60)
    print("1. æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®")
    print("=" * 60)
    
    google_api_key = os.getenv("GOOGLE_API_KEY", "")
    llm_provider = os.getenv("LLM_PROVIDER", "none")
    enable_intent = os.getenv("ENABLE_INTENT_ANALYSIS", "false")
    
    print(f"âœ“ LLM_PROVIDER: {llm_provider}")
    print(f"âœ“ GOOGLE_API_KEY: {'å·²é…ç½® (' + google_api_key[:10] + '...)' if google_api_key else 'æœªé…ç½®'}")
    print(f"âœ“ ENABLE_INTENT_ANALYSIS: {enable_intent}")
    
    if not google_api_key:
        print("\nâš ï¸  è­¦å‘Š: GOOGLE_API_KEY æœªé…ç½®")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GOOGLE_API_KEY")
        return False
    
    if llm_provider != "google":
        print(f"\nâš ï¸  è­¦å‘Š: LLM_PROVIDER è®¾ç½®ä¸º '{llm_provider}'ï¼Œåº”è¯¥æ˜¯ 'google'")
        return False
    
    print("\nâœ… ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®\n")
    return True


def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…å®‰è£…"""
    print("=" * 60)
    print("2. æµ‹è¯•ä¾èµ–åŒ…å®‰è£…")
    print("=" * 60)
    
    try:
        import google.generativeai as genai
        print("âœ“ google-generativeai å·²å®‰è£…")
        print(f"  ç‰ˆæœ¬: {genai.__version__ if hasattr(genai, '__version__') else 'æœªçŸ¥'}")
    except ImportError:
        print("âœ— google-generativeai æœªå®‰è£…")
        print("  è¯·è¿è¡Œ: pip install google-generativeai")
        return False
    
    try:
        import tiktoken
        print("âœ“ tiktoken å·²å®‰è£…")
    except ImportError:
        print("âš ï¸  tiktoken æœªå®‰è£…ï¼ˆå¯é€‰ï¼‰")
    
    print("\nâœ… ä¾èµ–åŒ…å®‰è£…æ­£ç¡®\n")
    return True


def test_llm_service():
    """æµ‹è¯• LLM æœåŠ¡åˆå§‹åŒ–"""
    print("=" * 60)
    print("3. æµ‹è¯• LLM æœåŠ¡åˆå§‹åŒ–")
    print("=" * 60)
    
    try:
        from app.services.llm_service import get_llm_service
        
        service = get_llm_service()
        
        if service is None:
            print("âœ— LLM æœåŠ¡æœªå¯ç”¨")
            print("  è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®")
            return False
        
        print(f"âœ“ LLM æœåŠ¡å·²åˆ›å»º: {service.__class__.__name__}")
        
        if service.is_available():
            print("âœ“ LLM æœåŠ¡å¯ç”¨")
        else:
            print("âœ— LLM æœåŠ¡ä¸å¯ç”¨")
            return False
        
        print("\nâœ… LLM æœåŠ¡åˆå§‹åŒ–æˆåŠŸ\n")
        return True
    
    except Exception as e:
        print(f"âœ— LLM æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


async def test_api_call():
    """æµ‹è¯• API è°ƒç”¨"""
    print("=" * 60)
    print("4. æµ‹è¯• Gemini API è°ƒç”¨")
    print("=" * 60)
    
    try:
        from app.services.llm_service import get_llm_service
        
        service = get_llm_service()
        if not service:
            print("âœ— LLM æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡ API æµ‹è¯•")
            return False
        
        print("æ­£åœ¨è°ƒç”¨ Gemini API...")
        
        # æµ‹è¯•ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ
        response = await service.generate_text(
            "Say 'Hello, I am Gemini!' in one sentence.",
            temperature=0.7,
            max_tokens=50
        )
        
        print(f"âœ“ API å“åº”: {response}")
        
        print("\nâœ… Gemini API è°ƒç”¨æˆåŠŸ\n")
        return True
    
    except Exception as e:
        print(f"âœ— API è°ƒç”¨å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„åŸå› :")
        print("  1. API Key æ— æ•ˆ")
        print("  2. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("  3. API é…é¢å·²ç”¨å®Œ")
        return False


async def test_tool_selection():
    """æµ‹è¯•å·¥å…·é€‰æ‹©"""
    print("=" * 60)
    print("5. æµ‹è¯•å·¥å…·é€‰æ‹©åŠŸèƒ½")
    print("=" * 60)
    
    try:
        from app.services.llm_service import get_llm_service
        
        service = get_llm_service()
        if not service:
            print("âœ— LLM æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡å·¥å…·é€‰æ‹©æµ‹è¯•")
            return False
        
        test_query = "æœ€è¿‘ OpenAI æœ‰ä»€ä¹ˆæ–°è¿›å±•ï¼Ÿ"
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        print("æ­£åœ¨é€‰æ‹©å·¥å…·...")
        
        # æ¨¡æ‹Ÿå·¥å…·æè¿°
        tools_description = """Available tools:
1. get_latest_news - Get the latest AI news articles
   Parameters: count (int, optional), keywords (list, optional)
2. search_news - Search for specific topics
   Parameters: query (str, required), count (int, optional)
"""
        
        tool_call = await service.select_tool(test_query, tools_description)
        
        print(f"\nâœ“ å·¥å…·é€‰æ‹©ç»“æœ:")
        print(f"  å·¥å…·: {tool_call.tool_name}")
        print(f"  å‚æ•°: {tool_call.parameters}")
        print(f"  ç½®ä¿¡åº¦: {tool_call.confidence}")
        print(f"  æ¨ç†: {tool_call.reasoning}")
        
        print("\nâœ… å·¥å…·é€‰æ‹©åŠŸèƒ½æ­£å¸¸\n")
        return True
    
    except Exception as e:
        print(f"âœ— å·¥å…·é€‰æ‹©å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "=" * 60)
    print("LLM è®¾ç½®æµ‹è¯•")
    print("=" * 60 + "\n")
    
    results = []
    
    # 1. æµ‹è¯•ç¯å¢ƒå˜é‡
    results.append(("ç¯å¢ƒå˜é‡", test_environment()))
    
    # 2. æµ‹è¯•ä¾èµ–
    results.append(("ä¾èµ–åŒ…", test_dependencies()))
    
    # 3. æµ‹è¯•æœåŠ¡åˆå§‹åŒ–
    results.append(("æœåŠ¡åˆå§‹åŒ–", test_llm_service()))
    
    # 4. æµ‹è¯• API è°ƒç”¨
    results.append(("API è°ƒç”¨", await test_api_call()))
    
    # 5. æµ‹è¯•å·¥å…·é€‰æ‹©
    results.append(("å·¥å…·é€‰æ‹©", await test_tool_selection()))
    
    # æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLM é›†æˆé…ç½®æ­£ç¡®ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
    print("=" * 60 + "\n")
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    import asyncio
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
