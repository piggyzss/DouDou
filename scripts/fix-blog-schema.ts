import { Pool } from 'pg'
import * as dotenv from 'dotenv'

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config({ path: '.env.local' })

function getDatabaseConfig() {
  if (process.env.DATABASE_URL || process.env.POSTGRES_URL) {
    return {
      connectionString: process.env.DATABASE_URL || process.env.POSTGRES_URL,
      ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
    }
  }
  
  return {
    host: process.env.DB_HOST || 'localhost',
    port: parseInt(process.env.DB_PORT || '5432'),
    database: process.env.DB_NAME || 'doudou_db',
    user: process.env.DB_USER || 'doudou_user',
    password: process.env.DB_PASSWORD || '',
  }
}

const pool = new Pool(getDatabaseConfig())

async function checkAndFixBlogSchema() {
  console.log('ğŸ” æ£€æŸ¥ blog_posts è¡¨ç»“æ„...')
  
  try {
    // æ£€æŸ¥å½“å‰è¡¨ç»“æ„
    const result = await pool.query(`
      SELECT column_name, data_type, is_nullable, column_default
      FROM information_schema.columns 
      WHERE table_name = 'blog_posts' 
      ORDER BY ordinal_position
    `)
    
    console.log('\nğŸ“Š å½“å‰ blog_posts è¡¨ç»“æ„:')
    console.log('åˆ—å | æ•°æ®ç±»å‹ | å¯ä¸ºç©º | é»˜è®¤å€¼')
    console.log('-'.repeat(60))
    
    const existingColumns = new Set()
    result.rows.forEach(row => {
      existingColumns.add(row.column_name)
      console.log(`${row.column_name} | ${row.data_type} | ${row.is_nullable} | ${row.column_default || 'NULL'}`)
    })
    
    // æ£€æŸ¥éœ€è¦æ·»åŠ çš„å­—æ®µ
    const requiredColumns = [
      { name: 'published_at', type: 'TIMESTAMP', nullable: true },
      { name: 'excerpt', type: 'TEXT', nullable: true },
      { name: 'cover_url', type: 'VARCHAR(500)', nullable: true },
      { name: 'views_count', type: 'INTEGER', default: '0' },
      { name: 'likes_count', type: 'INTEGER', default: '0' },
      { name: 'comments_count', type: 'INTEGER', default: '0' }
    ]
    
    console.log('\nğŸ”§ æ£€æŸ¥ç¼ºå°‘çš„å­—æ®µ...')
    const missingColumns = []
    
    for (const col of requiredColumns) {
      if (!existingColumns.has(col.name)) {
        missingColumns.push(col)
        console.log(`âŒ ç¼ºå°‘å­—æ®µ: ${col.name}`)
      } else {
        console.log(`âœ… å­—æ®µå­˜åœ¨: ${col.name}`)
      }
    }
    
    // æ·»åŠ ç¼ºå°‘çš„å­—æ®µ
    if (missingColumns.length > 0) {
      console.log('\nğŸ› ï¸ æ­£åœ¨æ·»åŠ ç¼ºå°‘çš„å­—æ®µ...')
      
      for (const col of missingColumns) {
        let sql = `ALTER TABLE blog_posts ADD COLUMN ${col.name} ${col.type}`
        
        if (col.default) {
          sql += ` DEFAULT ${col.default}`
        }
        
        console.log(`æ‰§è¡Œ: ${sql}`)
        await pool.query(sql)
        console.log(`âœ… å·²æ·»åŠ å­—æ®µ: ${col.name}`)
      }
    } else {
      console.log('\nâœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å·²å­˜åœ¨!')
    }
    
    // æ£€æŸ¥å¹¶åˆ›å»ºç´¢å¼•
    console.log('\nğŸ” æ£€æŸ¥ç´¢å¼•...')
    const indexResult = await pool.query(`
      SELECT indexname, indexdef 
      FROM pg_indexes 
      WHERE tablename = 'blog_posts'
    `)
    
    console.log('ç°æœ‰ç´¢å¼•:')
    indexResult.rows.forEach(row => {
      console.log(`- ${row.indexname}`)
    })
    
    // åˆ›å»ºç¼ºå°‘çš„ç´¢å¼•
    const requiredIndexes = [
      'CREATE INDEX IF NOT EXISTS idx_blog_posts_slug ON blog_posts(slug)',
      'CREATE INDEX IF NOT EXISTS idx_blog_posts_status ON blog_posts(status)',
      'CREATE INDEX IF NOT EXISTS idx_blog_posts_published_at ON blog_posts(published_at)',
      'CREATE INDEX IF NOT EXISTS idx_blog_posts_created_at ON blog_posts(created_at)'
    ]
    
    console.log('\nğŸ› ï¸ åˆ›å»ºç´¢å¼•...')
    for (const indexSql of requiredIndexes) {
      await pool.query(indexSql)
      console.log(`âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ: ${indexSql.split(' ON ')[0].split(' ').pop()}`)
    }
    
    console.log('\nğŸ‰ blog_posts è¡¨ç»“æ„ä¿®å¤å®Œæˆ!')
    
  } catch (error) {
    console.error('âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error)
  } finally {
    await pool.end()
  }
}

checkAndFixBlogSchema()
